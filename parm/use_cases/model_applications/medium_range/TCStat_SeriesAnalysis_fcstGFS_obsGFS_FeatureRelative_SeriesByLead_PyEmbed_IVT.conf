#
#  CONFIGURATION
#
[config]

# Loop over each process in the process list (set in PROCESS_LIST) for all times in the time window of interest.
LOOP_ORDER = processes

#Configuration files
TC_PAIRS_CONFIG_FILE = {CONFIG_DIR}/TCPairsETCConfig_IVT

SERIES_ANALYSIS_CONFIG_FILE = {CONFIG_DIR}/SeriesAnalysisConfig_IVT

PROCESS_LIST = PyEmbedIngest, TCPairs, TCStat, ExtractTiles, SeriesByLead

SERIES_ANALYSIS_REGRID_TO_GRID = FCST

# NOTE: "TOTAL" is a REQUIRED cnt statistic used by the series analysis scripts
SERIES_ANALYSIS_STAT_LIST = TOTAL, FBAR, OBAR, ME

# The init time begin and end times, increment
# Looping - options are INIT, VALID, RETRO, and REALTIME 
LOOP_BY = INIT

# Format of INIT_BEG and INIT_END
INIT_TIME_FMT = %Y%m%d%H

# Start time for METplus run
INIT_BEG = 2019083000

# End time for METplus run
INIT_END = 2019083023

# This is the step-size. Increment in seconds from the begin time to the end time
INIT_INCREMENT = 21600 ;; set to every 6 hours=21600 seconds

# Used by extract tiles and series analysis to define the records of
#  interest to be retrieved from the grib2 file 

BOTH_VAR1_NAME = ivt
BOTH_VAR1_LEVELS = Surface

# if true, run series_by_lead for groups of forecasts
# must set LEAD_SEQ_[N] and LEAD_SEQ_[N]_LABELS for N > 0 groups
# if false, run series_by_lead for all forecast hours
# must set LEAD_SEQ
SERIES_ANALYSIS_GROUP_FCSTS = False

LEAD_SEQ = 90, 96, 102, 108, 114

#####
### PYEMBED INGEST
#####

# 1st INGEST INSTANCE: Forecast
# python script with optional arguments to run for 1st ingest instance
PY_EMBED_INGEST_1_SCRIPT = {CONFIG_DIR}/gfs_ivt_fcst.py {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%HHH}.grb2

# type of python input to expect for 1st ingest instance
# valid options: NUMPY, XARRAY
PY_EMBED_INGEST_1_TYPE = NUMPY

# output grid for 1st ingest instance. Can be a grid definition or file path
PY_EMBED_INGEST_1_OUTPUT_GRID = {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%HHH}.grb2

# output variable name
PY_EMBED_INGEST_1_OUTPUT_FIELD_NAME = ivt

# 2nd INGEST INSTANCE: Analysis
# python script with optional arguments to run for 2nd ingest instance
PY_EMBED_INGEST_2_SCRIPT = {CONFIG_DIR}/gfs_ivt_analysis.py {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2

# type of python input to expect for 2nd ingest instance
# valid options: NUMPY, XARRAY
PY_EMBED_INGEST_2_TYPE = NUMPY

# output grid for 2nd ingest instance. Can be a grid definition or file path
PY_EMBED_INGEST_2_OUTPUT_GRID = {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2

# output variable name
PY_EMBED_INGEST_2_OUTPUT_FIELD_NAME = ivt

#######
# TCPairs Configurations
#######

# A list of times to include, in format YYYYMMDD_hh
TC_PAIRS_INIT_INCLUDE =

# A list of times to exclude, in format YYYYMMDD_hh
TC_PAIRS_INIT_EXCLUDE =

# Specify model valid time window in format YYYYMM[DD[_hh]].  Only tracks
# that fall within the valid time window will be used.
TC_PAIRS_VALID_BEG =
TC_PAIRS_VALID_END =

#
# Run MET tc_pairs by indicating the top-level directories for the A-deck
# and B-deck files. Set to 'yes' to run using top-level directories, 'no'
# if you want to run tc_pairs on files paired by the wrapper.
TC_PAIRS_READ_ALL_FILES = no

# List of models to be used (white space or comma separated) eg: DSHP, LGEM, HWRF
# If no models are listed, then process all models in the input file(s).
MODEL = GFSO

# List of storm ids of interest (space or comma separated) e.g.: AL112012, AL122012
# If no storm ids are listed, then process all storm ids in the input file(s).
TC_PAIRS_STORM_ID =

# Basins (of origin/region).  Indicate with space or comma-separated list of regions, eg. AL: for North Atlantic,
# WP: Western North Pacific, CP: Central North Pacific, SH: Southern Hemisphere, IO: North Indian Ocean, LS: Southern
# Hemisphere
TC_PAIRS_BASIN =

# Cyclone, a space or comma-separated list of cyclone numbers. If left empty, all cyclones will be used.
TC_PAIRS_CYCLONE =

# Storm name, a space or comma-separated list of storm names to evaluate.  If left empty, all storms will be used.
TC_PAIRS_STORM_NAME =

# DLAND file, the full path of the file that contains the gridded representation of the
# minimum distance from land.
TC_PAIRS_DLAND_FILE = {MET_INSTALL_DIR}/share/met/tc_data/dland_global_tenth_degree.nc

TC_PAIRS_REFORMAT_DECK = no
TC_PAIRS_REFORMAT_TYPE = SBU

TC_PAIRS_MISSING_VAL_TO_REPLACE = -99
TC_PAIRS_MISSING_VAL = -9999

# overwrite modified track data (non-ATCF to ATCF format)
TC_PAIRS_SKIP_IF_REFORMAT_EXISTS = no

# overwrite tc_pairs output
TC_PAIRS_SKIP_IF_OUTPUT_EXISTS = no

#######
# TCStat Configurations
#######
# IMPORTANT  Refer to the README_TC for details on setting up analysis
# jobs (located in {MET_INSTALL_DIR}/share/met/config

# Separate each option and value with whitespace, and each job with a whitespace.
# No whitespace within arithmetic expressions or lists of items
# (e.g. -by AMSLP,AMODEL,LEAD -column '(AMAX_WIND-BMAX_WIND)')
# Enclose your arithmetic expressions with '' and separate each job
# by whitespace:
#  -job filter -dump_row /path/to,  -job summary -line_type TCMPR  -column 'ABS(AMAX_WIND-BMAX_WIND)' -out {OUTPUT_BASE}/tc_stat/file.tcst

TC_STAT_JOB_ARGS = -job filter -basin AL -dump_row {TC_STAT_OUTPUT_DIR}/{TC_STAT_OUTPUT_TEMPLATE}

# Specify whether only those track points common to both the ADECK and BDECK
# tracks should be written out.  This is only used when explicitly calling
# TC_STAT in the PROCESS_LIST.  This is not used in this use case, so setting
# it to either false or true has no impact.
TC_STAT_MATCH_POINTS = true

# These all map to the options in the default TC-Stat config file, except these
# are pre-pended with TC_STAT to avoid clashing with any other similarly
# named options from other MET tools (eg TC_STAT_AMODEL corresponds to the
# amodel option in the default MET tc-stat config file, whereas AMODEL
# corresponds to the amodel option in the MET tc-pairs config file).

# Stratify by these columns:
TC_STAT_AMODEL = {MODEL}
TC_STAT_BMODEL =
TC_STAT_DESC =
TC_STAT_STORM_ID =
TC_STAT_BASIN =
TC_STAT_CYCLONE =
TC_STAT_STORM_NAME =

# Stratify by init times via a comma-separate list of init times to
# include or exclude.  Time format defined as YYYYMMDD_HH or YYYYMMDD_HHmmss
TC_STAT_INIT_BEG =
TC_STAT_INIT_END =
TC_STAT_INIT_INCLUDE = {init?fmt=%Y%m%d_%H}
TC_STAT_INIT_EXCLUDE =
TC_STAT_INIT_HOUR =  
# Stratify by valid times via a comma-separate list of valid times to
# include or exclude.  Time format defined as YYYYMMDD_HH or YYYYMMDD_HHmmss
TC_STAT_VALID_BEG =
TC_STAT_VALID_END = 
TC_STAT_VALID_INCLUDE =
TC_STAT_VALID_EXCLUDE =
TC_STAT_VALID_HOUR =
TC_STAT_LEAD_REQ =
TC_STAT_INIT_MASK =
TC_STAT_VALID_MASK =
# Stratify by the valid time and lead time via comma-separated list of
# times in format HH[MMSS]
TC_STAT_VALID_HOUR =
TC_STAT_LEAD =

# Stratify over the watch_warn column in the tcst file.  Setting this to
# 'ALL' will match HUWARN, HUWATCH, TSWARN, TSWATCH
TC_STAT_TRACK_WATCH_WARN =

# Stratify by applying thresholds to numeric data columns.  Specify with
# comma-separated list of column names and thresholds to be applied.
# The length of TC_STAT_COLUMN_THRESH_NAME should be the same as
# TC_STAT_COLUMN_THRESH_VAL.
TC_STAT_COLUMN_THRESH_NAME =
TC_STAT_COLUMN_THRESH_VAL =

# Stratify by a list of comma-separated columns names and values corresponding
# to non-numeric data columns of the values of interest.
TC_STAT_COLUMN_STR_NAME =
TC_STAT_COLUMN_STR_VAL =

# Stratify by applying thresholds to numeric data columns only when lead=0.
# If lead=0 and the value does not meet the threshold, discard the entire
# track.  The length of TC_STAT_INIT_THRESH_NAME must equal the length of
# TC_STAT_INIT_THRESH_VAL.
TC_STAT_INIT_THRESH_NAME =
TC_STAT_INIT_THRESH_VAL =

# Stratify by applying thresholds to numeric data columns only when lead = 0.
# If lead = 0 but the value doesn't meet the threshold, discard the entire
# track.
TC_STAT_INIT_STR_NAME =
TC_STAT_INIT_STR_VAL =

# Excludes any points where distance to land is <=0. When set to TRUE, once land
# is encountered, the remainder of the forecast track is NOT used for the
# verification, even if the track moves back over water.
TC_STAT_WATER_ONLY =

# TRUE or FALSE.  To specify whether only those track points occurring near
# landfall should be retained. Landfall is the last bmodel track point before
# the distance to land switches from water to land.
TC_STAT_LANDFALL =

# Define the landfall retention window, which is defined as the hours offset
# from the time of landfall. Format is in HH[MMSS]. Default TC_STAT_LANDFALL_BEG
# is set to -24, and TC_STAT_LANDFALL_END is set to 00
TC_STAT_LANDFALL_BEG = -24
TC_STAT_LANDFALL_END = 00

#######
# ExtractTiles Configurations
#######

# Constants used in creating the tile grid, used by extract tiles
EXTRACT_TILES_NLAT = 60
EXTRACT_TILES_NLON = 60

# Resolution of data in degrees, used by extract tiles
EXTRACT_TILES_DLAT = 0.5
EXTRACT_TILES_DLON = 0.5

# Degrees to subtract from the center lat and lon to
# calculate the lower left lat (lat_ll) and lower
# left lon (lon_ll) for a grid that is 2n X 2m,
# where n = EXTRACT_TILES_LAT_ADJ degrees and m = EXTRACT_TILES_LON_ADJ degrees.
# For this case, where n=15 and m=15, this results
# in a 30 deg X 30 deg grid.  Used by extract tiles
EXTRACT_TILES_LON_ADJ = 15
EXTRACT_TILES_LAT_ADJ = 15

# OVERWRITE OPTIONS
# Skip writing filter files if they already exist.
# Set to yes if you want to skip processing existing files
# Set to no if you want to override existing files
EXTRACT_TILES_SKIP_IF_OUTPUT_EXISTS = no

#######
# SeriesAnalysis Configurations
#######

SERIES_ANALYSIS_FILTER_OPTS =

# PLOTTING Relevant to series analysis plots.
# By default, background map is turned off. Set
# to no to turn of plotting of background map.
SERIES_ANALYSIS_BACKGROUND_MAP = yes

#
#  FILENAME TEMPLATES
#
[filename_templates]
# Define the format of the filenames
PY_EMBED_INGEST_1_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%HHH}.nc
PY_EMBED_INGEST_2_OUTPUT_TEMPLATE = {valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.nc

TC_PAIRS_ADECK_TEMPLATE = a{basin?fmt=%s}{cyclone?fmt=%s}{date?fmt=%Y}.dat
TC_PAIRS_BDECK_TEMPLATE = b{basin?fmt=%s}{cyclone?fmt=%s}{date?fmt=%Y}.dat
TC_PAIRS_OUTPUT_TEMPLATE = {date?fmt=%Y%m}/{basin?fmt=%s}q{date?fmt=%Y%m%d%H}.dorian

TC_STAT_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d_%H}/filter_{init?fmt=%Y%m%d_%H}.tcst

EXTRACT_TILES_STAT_INPUT_TEMPLATE = {TC_STAT_OUTPUT_TEMPLATE}
FCST_EXTRACT_TILES_INPUT_TEMPLATE = {init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%HHH}.nc
OBS_EXTRACT_TILES_INPUT_TEMPLATE = {valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.nc

FCST_EXTRACT_TILES_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d_%H}/{storm_id}/FCST_TILE_F{lead?fmt=%HHH}_{amodel}_gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%HHH}.nc
OBS_EXTRACT_TILES_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d_%H}/{storm_id}/ANLY_TILE_F{lead?fmt=%HHH}_{amodel}_gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.nc

#
#  DIRECTORIES
#
[dir]

# location of configuration files used by MET applications
CONFIG_DIR={PARM_BASE}/use_cases/model_applications/medium_range

#Location of model data
MODEL_DIR = {INPUT_BASE}/model_applications/medium_range/dorian_data/model_data

PY_EMBED_INGEST_1_OUTPUT_DIR = {OUTPUT_BASE}/py_embed_out
PY_EMBED_INGEST_2_OUTPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}

# track data, set to your data source
TC_PAIRS_ADECK_INPUT_DIR = {INPUT_BASE}/model_applications/medium_range/dorian_data/track_data
TC_PAIRS_BDECK_INPUT_DIR = {TC_PAIRS_ADECK_INPUT_DIR}
TC_PAIRS_REFORMAT_DIR = {OUTPUT_BASE}/track_data_atcf
TC_PAIRS_OUTPUT_DIR = {OUTPUT_BASE}/tc_pairs

TC_STAT_LOOKIN_DIR = {TC_PAIRS_OUTPUT_DIR}
TC_STAT_OUTPUT_DIR = {EXTRACT_TILES_OUTPUT_DIR}

EXTRACT_TILES_STAT_INPUT_DIR = {TC_STAT_OUTPUT_DIR}
EXTRACT_TILES_GRID_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
FCST_EXTRACT_TILES_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
OBS_EXTRACT_TILES_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
EXTRACT_TILES_OUTPUT_DIR = {OUTPUT_BASE}/extract_tiles

SERIES_ANALYSIS_INPUT_DIR = {EXTRACT_TILES_OUTPUT_DIR}
SERIES_ANALYSIS_FILTERED_OUTPUT_DIR = {OUTPUT_BASE}/series_lead_filtered

# Define the output directories for Series analysis by lead and init
SERIES_ANALYSIS_OUTPUT_DIR = {OUTPUT_BASE}/series_analysis_lead

#
#  REGEX PATTERNS
#
[regex_pattern]
# Regular expressions that are used in series analysis
# Forecast and Analysis tile files, and ASCII files
# created by the series analysis by init and lead time

# Indicate the prefix to the output netCDF files generated by 
# MET series_analysis
# For example, MET will produce files with the following format:
#  <prefix>__F018_gfs_4_20141215_0000_018.nc
# and the <prefix> enables the user to distinguish the forecast
# files from the analysis files
FCST_EXTRACT_TILES_PREFIX = FCST_TILE_F
OBS_EXTRACT_TILES_PREFIX = ANLY_TILE_F


#
# Indicate the regular expression of the files that were created by the
# extract tiles wrapper.  This information is used to check that input tiles
# exist before proceeding with the series analysis process.
#
# These are the forecast and analysis input files that are expected if regridding
# is to be performed by MET regrid_data_plane
FCST_SERIES_ANALYSIS_TILE_REGEX = .*FCST_TILE_F.*.grb2
OBS_SERIES_ANALYSIS_TILE_REGEX = .*ANLY_TILE_F.*.grb2

# These are the forecast and analysis input files that are expected if regridding
# is to be done via the NOAA wgrib2 tool.
FCST_SERIES_ANALYSIS_NC_TILE_REGEX = .*FCST_TILE_F.*.nc
OBS_SERIES_ANALYSIS_NC_TILE_REGEX = .*ANLY_TILE_F.*.nc

# The regular expression describing the format of the forecast and analysis files 
# that contain a list of the gridded files included in the series analysis.  This
# information is used to clean up pre-existing forecast and analysis files.
FCST_SERIES_ANALYSIS_ASCII_REGEX_LEAD = FCST_FILE_F.*
OBS_SERIES_ANALYSIS_ASCII_REGEX_LEAD = ANLY_FILE_F.*

[exe]
