#
#  CONFIGURATION
#
[config]

# Loop over each process in the process list (set in PROCESS_LIST) for all times in the time window of interest.
LOOP_ORDER = processes

#Configuration files
TC_PAIRS_CONFIG_FILE = {PARM_BASE}/met_config/TCPairsConfig_wrapped

SERIES_ANALYSIS_CONFIG_FILE = {PARM_BASE}/met_config/SeriesAnalysisConfig_wrapped

PROCESS_LIST = PyEmbedIngest, TCPairs, TCStat, ExtractTiles, TCStat(for_series_analysis), SeriesAnalysis

# The init time begin and end times, increment
# Looping - options are INIT, VALID, RETRO, and REALTIME 
LOOP_BY = INIT

# Format of INIT_BEG and INIT_END
INIT_TIME_FMT = %Y%m%d%H

# Start time for METplus run
INIT_BEG = 2019083000

# End time for METplus run
INIT_END = 2019083023

# This is the step-size. Increment in seconds from the begin time to the end time
INIT_INCREMENT = 21600 ;; set to every 6 hours=21600 seconds

# Used by extract tiles and series analysis to define the records of
#  interest to be retrieved from the grib2 file 

BOTH_VAR1_NAME = ivt
BOTH_VAR1_LEVELS = Surface

BOTH_VAR2_NAME = pv
BOTH_VAR2_LEVELS = Surface

BOTH_VAR3_NAME = sept
BOTH_VAR3_LEVELS = Surface

LEAD_SEQ = 90, 96, 102, 108, 114

#####
### PYEMBED INGEST
#####

# 1st INGEST INSTANCE: Forecast
# python script with optional arguments to run for 1st ingest instance
# IVT
PY_EMBED_INGEST_1_SCRIPT_1 = {CONFIG_DIR}/gfs_ivt_fcst.py {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.grb2
# output variable name
PY_EMBED_INGEST_1_OUTPUT_FIELD_NAME_1 = ivt

# PV
# python script with optional arguments to run for 1st ingest instance
PY_EMBED_INGEST_1_SCRIPT_2 = {CONFIG_DIR}/gfs_pv_fcst.py {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.grb2
# output variable name
PY_EMBED_INGEST_1_OUTPUT_FIELD_NAME_2 = pv

# SEPT
# python script with optional arguments to run for 1st ingest instance
PY_EMBED_INGEST_1_SCRIPT_3 = {CONFIG_DIR}/gfs_sept_fcst.py {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.grb2
# output variable name
PY_EMBED_INGEST_1_OUTPUT_FIELD_NAME_3 = sept

# type of python input to expect for 1st ingest instance
# valid options: NUMPY, XARRAY
PY_EMBED_INGEST_1_TYPE = NUMPY

# output grid for 1st ingest instance. Can be a grid definition or file path
PY_EMBED_INGEST_1_OUTPUT_GRID = {MODEL_DIR}/{init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.grb2

# 2nd INGEST INSTANCE: Analysis
# IVT
# python script with optional arguments to run for 2nd ingest instance
PY_EMBED_INGEST_2_SCRIPT_1 = {CONFIG_DIR}/gfs_ivt_analysis.py {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2
# output variable name
PY_EMBED_INGEST_2_OUTPUT_FIELD_NAME_1 = ivt

# PV
# python script with optional arguments to run for 2nd ingest instance
PY_EMBED_INGEST_2_SCRIPT_2 = {CONFIG_DIR}/gfs_pv_analysis.py {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2
# output variable name
PY_EMBED_INGEST_2_OUTPUT_FIELD_NAME_2 = pv

# SEPT
# python script with optional arguments to run for 2nd ingest instance
PY_EMBED_INGEST_2_SCRIPT_3 = {CONFIG_DIR}/gfs_sept_analysis.py {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2
# output variable name
PY_EMBED_INGEST_2_OUTPUT_FIELD_NAME_3 = sept

# type of python input to expect for 2nd ingest instance
# valid options: NUMPY, XARRAY
PY_EMBED_INGEST_2_TYPE = NUMPY

# output grid for 2nd ingest instance. Can be a grid definition or file path
PY_EMBED_INGEST_2_OUTPUT_GRID = {MODEL_DIR}/{valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.grb2

#######
# TCPairs Configurations
#######

# only run TCPairs once for the init time, not for each forecast lead
TC_PAIRS_SKIP_LEAD_SEQ = True

# A list of times to include, in format YYYYMMDD_hh
TC_PAIRS_INIT_INCLUDE =

# A list of times to exclude, in format YYYYMMDD_hh
TC_PAIRS_INIT_EXCLUDE =

# Specify model valid time window in format YYYYMM[DD[_hh]].  Only tracks
# that fall within the valid time window will be used.
TC_PAIRS_VALID_BEG =
TC_PAIRS_VALID_END =

#
# Run MET tc_pairs by indicating the top-level directories for the A-deck
# and B-deck files. Set to 'yes' to run using top-level directories, 'no'
# if you want to run tc_pairs on files paired by the wrapper.
TC_PAIRS_READ_ALL_FILES = no

# List of models to be used (white space or comma separated) eg: DSHP, LGEM, HWRF
# If no models are listed, then process all models in the input file(s).
MODEL = GFSO

# List of storm ids of interest (space or comma separated) e.g.: AL112012, AL122012
# If no storm ids are listed, then process all storm ids in the input file(s).
TC_PAIRS_STORM_ID =

# Basins (of origin/region).  Indicate with space or comma-separated list of regions, eg. AL: for North Atlantic,
# WP: Western North Pacific, CP: Central North Pacific, SH: Southern Hemisphere, IO: North Indian Ocean, LS: Southern
# Hemisphere
TC_PAIRS_BASIN =

# Cyclone, a space or comma-separated list of cyclone numbers. If left empty, all cyclones will be used.
TC_PAIRS_CYCLONE =

# Storm name, a space or comma-separated list of storm names to evaluate.  If left empty, all storms will be used.
TC_PAIRS_STORM_NAME =

# DLAND file, the full path of the file that contains the gridded representation of the
# minimum distance from land.
TC_PAIRS_DLAND_FILE = {MET_INSTALL_DIR}/share/met/tc_data/dland_global_tenth_degree.nc

TC_PAIRS_REFORMAT_DECK = no
TC_PAIRS_REFORMAT_TYPE = SBU

TC_PAIRS_MISSING_VAL_TO_REPLACE = -99
TC_PAIRS_MISSING_VAL = -9999

# overwrite modified track data (non-ATCF to ATCF format)
TC_PAIRS_SKIP_IF_REFORMAT_EXISTS = no

# overwrite tc_pairs output
TC_PAIRS_SKIP_IF_OUTPUT_EXISTS = no

#######
# TCStat Configurations
#######

# IMPORTANT  Refer to the README_TC for details on setting up analysis
# jobs (located in {MET_INSTALL_DIR}/share/met/config

# Separate each option and value with whitespace, and each job with a whitespace.
# No whitespace within arithmetic expressions or lists of items
# (e.g. -by AMSLP,AMODEL,LEAD -column '(AMAX_WIND-BMAX_WIND)')
# Enclose your arithmetic expressions with '' and separate each job
# by whitespace:
#  -job filter -dump_row /path/to,  -job summary -line_type TCMPR  -column 'ABS(AMAX_WIND-BMAX_WIND)' -out {OUTPUT_BASE}/tc_stat/file.tcst

TC_STAT_JOB_ARGS = -job filter -basin AL -dump_row {TC_STAT_OUTPUT_DIR}/{TC_STAT_DUMP_ROW_TEMPLATE}


# Specify whether only those track points common to both the ADECK and BDECK
# tracks should be written out.  This is only used when explicitly calling
# TC_STAT in the PROCESS_LIST.  This is not used in this use case, so setting
# it to either false or true has no impact.
TC_STAT_MATCH_POINTS = true

# Stratify by these columns:
TC_STAT_AMODEL = {MODEL}
TC_STAT_BMODEL =
TC_STAT_DESC =
TC_STAT_STORM_ID =
TC_STAT_BASIN =
TC_STAT_CYCLONE =
TC_STAT_STORM_NAME =

# Stratify by init times via a comma-separate list of init times to
# include or exclude.  Time format defined as YYYYMMDD_HH or YYYYMMDD_HHmmss
TC_STAT_INIT_BEG =
TC_STAT_INIT_END =
TC_STAT_INIT_INCLUDE = {init?fmt=%Y%m%d_%H}
TC_STAT_INIT_EXCLUDE =
TC_STAT_INIT_HOUR =  
# Stratify by valid times via a comma-separate list of valid times to
# include or exclude.  Time format defined as YYYYMMDD_HH or YYYYMMDD_HHmmss
TC_STAT_VALID_BEG =
TC_STAT_VALID_END = 
TC_STAT_VALID_INCLUDE =
TC_STAT_VALID_EXCLUDE =
TC_STAT_VALID_HOUR =
TC_STAT_LEAD_REQ =
TC_STAT_INIT_MASK =
TC_STAT_VALID_MASK =
# Stratify by the valid time and lead time via comma-separated list of
# times in format HH[MMSS]
TC_STAT_VALID_HOUR =
TC_STAT_LEAD =

# Stratify over the watch_warn column in the tcst file.  Setting this to
# 'ALL' will match HUWARN, HUWATCH, TSWARN, TSWATCH
TC_STAT_TRACK_WATCH_WARN =

# Stratify by applying thresholds to numeric data columns.  Specify with
# comma-separated list of column names and thresholds to be applied.
# The length of TC_STAT_COLUMN_THRESH_NAME should be the same as
# TC_STAT_COLUMN_THRESH_VAL.
TC_STAT_COLUMN_THRESH_NAME =
TC_STAT_COLUMN_THRESH_VAL =

# Stratify by a list of comma-separated columns names and values corresponding
# to non-numeric data columns of the values of interest.
TC_STAT_COLUMN_STR_NAME =
TC_STAT_COLUMN_STR_VAL =

# Stratify by applying thresholds to numeric data columns only when lead=0.
# If lead=0 and the value does not meet the threshold, discard the entire
# track.  The length of TC_STAT_INIT_THRESH_NAME must equal the length of
# TC_STAT_INIT_THRESH_VAL.
TC_STAT_INIT_THRESH_NAME =
TC_STAT_INIT_THRESH_VAL =

# Stratify by applying thresholds to numeric data columns only when lead = 0.
# If lead = 0 but the value doesn't meet the threshold, discard the entire
# track.
TC_STAT_INIT_STR_NAME =
TC_STAT_INIT_STR_VAL =

# Excludes any points where distance to land is <=0. When set to TRUE, once land
# is encountered, the remainder of the forecast track is NOT used for the
# verification, even if the track moves back over water.
TC_STAT_WATER_ONLY =

# TRUE or FALSE.  To specify whether only those track points occurring near
# landfall should be retained. Landfall is the last bmodel track point before
# the distance to land switches from water to land.
TC_STAT_LANDFALL =

# Define the landfall retention window, which is defined as the hours offset
# from the time of landfall. Format is in HH[MMSS]. Default TC_STAT_LANDFALL_BEG
# is set to -24, and TC_STAT_LANDFALL_END is set to 00
TC_STAT_LANDFALL_BEG =
TC_STAT_LANDFALL_END =


# Constants used in creating the tile grid, used by extract tiles
EXTRACT_TILES_NLAT = 60
EXTRACT_TILES_NLON = 60

# Resolution of data in degrees, used by extract tiles
EXTRACT_TILES_DLAT = 0.5
EXTRACT_TILES_DLON = 0.5

# Degrees to subtract from the center lat and lon to
# calculate the lower left lat (lat_ll) and lower
# left lon (lon_ll) for a grid that is 2n X 2m,
# where n = EXTRACT_TILES_LAT_ADJ degrees and m = EXTRACT_TILES_LON_ADJ degrees.
# For this case, where n=15 and m=15, this results
# in a 30 deg X 30 deg grid.  Used by extract tiles
EXTRACT_TILES_LON_ADJ = 15
EXTRACT_TILES_LAT_ADJ = 15

# OVERWRITE OPTIONS
# Skip writing filter files if they already exist.
# Set to yes if you want to skip processing existing files
# Set to no if you want to override existing files
EXTRACT_TILES_SKIP_IF_OUTPUT_EXISTS = no

# Settings specific to the TCStat(for_series_analysis) process that was set
# in the PROCESS_LIST. Any TC_STAT_* variable not set in this section will use
# the value set outside of this section
[for_series_analysis]
TC_STAT_JOB_ARGS = -job filter -init_beg {INIT_BEG} -init_end {INIT_END} -dump_row {TC_STAT_OUTPUT_DIR}/{TC_STAT_DUMP_ROW_TEMPLATE}

TC_STAT_OUTPUT_DIR = {SERIES_ANALYSIS_OUTPUT_DIR}
TC_STAT_LOOKIN_DIR = {EXTRACT_TILES_OUTPUT_DIR}

[config]

# set the regrid dictionary item to_grid in the SeriesAnalysis MET config file
SERIES_ANALYSIS_REGRID_TO_GRID = FCST
SERIES_ANALYSIS_REGRID_METHOD = FORCE
#SERIES_ANALYSIS_REGRID_WIDTH =
#SERIES_ANALYSIS_REGRID_VLD_THRESH =
#SERIES_ANALYSIS_REGRID_SHAPE =

# NOTE: "TOTAL" is a REQUIRED cnt statistic used by the series analysis scripts
SERIES_ANALYSIS_STAT_LIST = TOTAL, FBAR, OBAR, ME

# PLOTTING Relevant to series analysis plots.
# By default, background map is turned off. Set
# to no to turn of plotting of background map.
SERIES_ANALYSIS_BACKGROUND_MAP = yes

SERIES_ANALYSIS_RUNTIME_FREQ = RUN_ONCE_PER_LEAD

SERIES_ANALYSIS_RUN_ONCE_PER_STORM_ID = False

SERIES_ANALYSIS_BLOCK_SIZE = 4000

# set to True to add the -paired flag to the SeriesAnalysis command
SERIES_ANALYSIS_IS_PAIRED = True

# If True/yes, run plot_data_plane on output from Series-Analysis to generate
# images for each stat item listed in SERIES_ANALYSIS_STAT_LIST
SERIES_ANALYSIS_GENERATE_PLOTS = yes

# If True/yes, run convert on output from Series-Analysis to generate
# a gif using images in groups of name/level/stat
SERIES_ANALYSIS_GENERATE_ANIMATIONS = yes

PLOT_DATA_PLANE_TITLE = {MODEL} series_F{fcst_beg} Forecasts{nseries}, {stat} for {fcst_name} {fcst_level}

#
#  FILENAME TEMPLATES
#
[filename_templates]
# Define the format of the filenames
PY_EMBED_INGEST_1_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.nc
PY_EMBED_INGEST_2_OUTPUT_TEMPLATE = {valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.nc

TC_PAIRS_ADECK_TEMPLATE = a{basin?fmt=%s}052019.dat
TC_PAIRS_BDECK_TEMPLATE = b{basin?fmt=%s}052019.dat
TC_PAIRS_OUTPUT_TEMPLATE = {date?fmt=%Y%m}/{basin?fmt=%s}q{date?fmt=%Y%m%d%H}.dorian

TC_STAT_DUMP_ROW_TEMPLATE = filter_{init?fmt=%Y%m%d_%H}.tcst

EXTRACT_TILES_TC_STAT_INPUT_TEMPLATE = {TC_STAT_DUMP_ROW_TEMPLATE}
FCST_EXTRACT_TILES_INPUT_TEMPLATE = {init?fmt=%Y%m%d}/gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.nc
OBS_EXTRACT_TILES_INPUT_TEMPLATE = {valid?fmt=%Y%m%d}/gfs_4_{valid?fmt=%Y%m%d}_{valid?fmt=%H}00_000.nc

FCST_EXTRACT_TILES_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d_%H}/{storm_id}/FCST_TILE_F{lead?fmt=%3H}_{MODEL}_gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.nc
OBS_EXTRACT_TILES_OUTPUT_TEMPLATE = {init?fmt=%Y%m%d_%H}/{storm_id}/OBS_TILE_F{lead?fmt=%3H}_{MODEL}_gfs_4_{init?fmt=%Y%m%d}_{init?fmt=%H}00_{lead?fmt=%3H}.nc

FCST_SERIES_ANALYSIS_INPUT_TEMPLATE = {FCST_EXTRACT_TILES_OUTPUT_TEMPLATE}
OBS_SERIES_ANALYSIS_INPUT_TEMPLATE = {OBS_EXTRACT_TILES_OUTPUT_TEMPLATE}

SERIES_ANALYSIS_TC_STAT_INPUT_TEMPLATE = {TC_STAT_DUMP_ROW_TEMPLATE}


# Template to look for climatology mean input to SeriesAnalysis relative to SERIES_ANALYSIS_CLIMO_MEAN_INPUT_DIR
# Not used in this example
SERIES_ANALYSIS_CLIMO_MEAN_INPUT_TEMPLATE =

# Template to look for climatology standard deviation input to SeriesAnalysis relative to SERIES_ANALYSIS_CLIMO_STDEV_INPUT_DIR
# Not used in this example
SERIES_ANALYSIS_CLIMO_STDEV_INPUT_TEMPLATE =

SERIES_ANALYSIS_OUTPUT_TEMPLATE = {label}/series_F{fcst_beg}_{fcst_name}_{fcst_level}.nc
#
#  DIRECTORIES
#
[dir]

# location of configuration files used by MET applications
CONFIG_DIR={PARM_BASE}/use_cases/model_applications/medium_range/TCStat_SeriesAnalysis_fcstGFS_obsGFS_FeatureRelative_SeriesByLead_PyEmbed_Multiple_Diagnostics

#Location of model data
MODEL_DIR = {INPUT_BASE}/model_applications/medium_range/dorian_data/model_data


PY_EMBED_INGEST_1_OUTPUT_DIR = {OUTPUT_BASE}/py_embed_out
PY_EMBED_INGEST_2_OUTPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}

# track data, set to your data source
TC_PAIRS_ADECK_INPUT_DIR = {INPUT_BASE}/model_applications/medium_range/dorian_data/track_data
TC_PAIRS_BDECK_INPUT_DIR = {TC_PAIRS_ADECK_INPUT_DIR}
TC_PAIRS_REFORMAT_DIR = {OUTPUT_BASE}/track_data_atcf
TC_PAIRS_OUTPUT_DIR = {OUTPUT_BASE}/tc_pairs

TC_STAT_LOOKIN_DIR = {TC_PAIRS_OUTPUT_DIR}
TC_STAT_OUTPUT_DIR = {EXTRACT_TILES_OUTPUT_DIR}

EXTRACT_TILES_TC_STAT_INPUT_DIR = {TC_STAT_OUTPUT_DIR}
EXTRACT_TILES_GRID_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
FCST_EXTRACT_TILES_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
OBS_EXTRACT_TILES_INPUT_DIR = {PY_EMBED_INGEST_1_OUTPUT_DIR}
EXTRACT_TILES_OUTPUT_DIR = {OUTPUT_BASE}/extract_tiles

FCST_SERIES_ANALYSIS_INPUT_DIR = {EXTRACT_TILES_OUTPUT_DIR}
OBS_SERIES_ANALYSIS_INPUT_DIR = {EXTRACT_TILES_OUTPUT_DIR}
SERIES_ANALYSIS_TC_STAT_INPUT_DIR = {SERIES_ANALYSIS_OUTPUT_DIR}

# directory containing climatology mean input to SeriesAnalysis
# Not used in this example
SERIES_ANALYSIS_CLIMO_MEAN_INPUT_DIR =

# directory containing climatology standard deviation input to SeriesAnalysis
# Not used in this example
SERIES_ANALYSIS_CLIMO_STDEV_INPUT_DIR =

SERIES_ANALYSIS_OUTPUT_DIR = {OUTPUT_BASE}/series_analysis_lead

[user_env_vars]
PV_LAYER_MIN_PRESSURE=100.0
PV_LAYER_MAX_PRESSURE=1000.0
IVT_LAYER_MIN_PRESSURE=100.0
IVT_LAYER_MAX_PRESSURE=1000.0
SEPT_LAYER_MIN_PRESSURE=100.0
SEPT_LAYER_MAX_PRESSURE=1000.0
